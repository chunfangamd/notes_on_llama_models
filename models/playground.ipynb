{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch implementation of apply_scaling\n",
    "def apply_scaling(freqs: torch.Tensor):\n",
    "    # Values obtained from grid search\n",
    "    scale_factor = 8\n",
    "    low_freq_factor = 1\n",
    "    high_freq_factor = 4\n",
    "    old_context_len = 8192  # original llama3 length\n",
    "\n",
    "    low_freq_wavelen = old_context_len / low_freq_factor\n",
    "    high_freq_wavelen = old_context_len / high_freq_factor\n",
    "    new_freqs = []\n",
    "    for freq in freqs:\n",
    "        wavelen = 2 * np.pi / freq\n",
    "        if wavelen < high_freq_wavelen:\n",
    "            new_freqs.append(freq)\n",
    "        elif wavelen > low_freq_wavelen:\n",
    "            new_freqs.append(freq / scale_factor)\n",
    "        else:\n",
    "            assert low_freq_wavelen != high_freq_wavelen\n",
    "            smooth = (old_context_len / wavelen - low_freq_factor) / (\n",
    "                high_freq_factor - low_freq_factor\n",
    "            )\n",
    "            new_freqs.append((1 - smooth) * freq / scale_factor + smooth * freq)\n",
    "    return torch.tensor(new_freqs, dtype=freqs.dtype, device=freqs.device)\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(\n",
    "    dim: int, end: int, theta: float = 10000.0, use_scaled: bool = False\n",
    "):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device, dtype=torch.float32)\n",
    "    if use_scaled:\n",
    "        freqs = apply_scaling(freqs)\n",
    "    freqs = torch.outer(t, freqs)\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify `apply_scaling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input tensor\n",
    "# # freqs_np = np.array([0.1, 1.0, 10.0, 100.0, 1000.0], dtype=np.float32)\n",
    "# freqs_np = np.array([1.0000, 0.9822, 0.9647, 0.9475, 0.9306, 0.9140, 0.8977, 0.8817, 0.8660,\n",
    "#         0.8505], dtype=np.float32)\n",
    "\n",
    "# freqs_torch = torch.tensor(freqs_np)\n",
    "# scaled_freqs_torch = apply_scaling(freqs_torch).numpy()\n",
    "\n",
    "# print(\"PyTorch output:\", scaled_freqs_torch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify `precompute_freqs_cis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input parameters for testing\n",
    "# dim = 16\n",
    "# end = 10\n",
    "# theta = 10000.0\n",
    "# use_scaled = True\n",
    "\n",
    "# # PyTorch version\n",
    "# freqs_cis_torch = precompute_freqs_cis(dim, end, theta, use_scaled).numpy()\n",
    "\n",
    "# # Compare outputs\n",
    "# # print(\"PyTorch output:\", freqs_cis_torch)\n",
    "# print(freqs_cis_torch.shape )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify `reshape_for_broadcast` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input tensors for testing\n",
    "# np.random.seed(42)\n",
    "# x_shape = (2, 4, 8)\n",
    "# x_np = np.random.randn(*x_shape).astype(np.float32)\n",
    "# freqs_cis_np = np.random.randn(x_shape[1], x_shape[-1]).astype(np.complex64)\n",
    "# print(x_np)\n",
    "# print(freqs_cis_np)\n",
    "\n",
    "# x_torch = torch.tensor(x_np)\n",
    "# freqs_cis_torch = torch.tensor(freqs_cis_np)\n",
    "\n",
    "# reshaped_torch = reshape_for_broadcast(freqs_cis_torch, x_torch).numpy()\n",
    "\n",
    "# print(\"PyTorch output:\", reshaped_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify `apply_rotary_emb` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "\n",
    "# # Input tensors for testing\n",
    "# xq_shape = (1, 10, 4, 16)  # (batch_size, seq_len, num_heads, dim)\n",
    "# xk_shape = (1, 10, 4, 16)\n",
    "\n",
    "# xq_np = np.random.randn(*xq_shape).astype(np.float32)\n",
    "# xk_np = np.random.randn(*xk_shape).astype(np.float32)\n",
    "# freqs_cis_np = np.random.randn(xq_shape[1], xq_shape[-1]//2).astype(np.complex64)\n",
    "\n",
    "# xq_torch = torch.tensor(xq_np)\n",
    "# xk_torch = torch.tensor(xk_np)\n",
    "# freqs_cis_torch = torch.tensor(freqs_cis_np)\n",
    "\n",
    "# # PyTorch version\n",
    "# xq_out_torch, xk_out_torch = apply_rotary_emb(xq_torch, xk_torch, freqs_cis_torch)\n",
    "\n",
    "# # Compare outputs\n",
    "# print(\"PyTorch xq output:\", xq_out_torch)\n",
    "# print(\"PyTorch xk output:\", xk_out_torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = torch.ones((10, 10))\n",
    "ones_tril = torch.tril(ones).unsqueeze(0).unsqueeze(0)\n",
    "print(ones.shape)\n",
    "print(ones_tril.shape)\n",
    "ones_tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.tensor(list(range(3)))\n",
    "ones_tril.index_select(2, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
